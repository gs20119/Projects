{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml  \n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784', version=1) # 사이킷런에서 mnist 데이터 불러오기 (dictionary)\n",
    "mnist.keys() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = mnist[\"data\"], mnist[\"target\"] # 70000개의 데이터 : X[i] = 28x28 손글씨 이미지, y[i] = 레이블\n",
    "y = y.astype(np.uint8) # 문자열 형태 y를 정수로 변환\n",
    "print(\"X : {0}\".format(X.shape))\n",
    "print(\"y : {0}\".format(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_digit = X[913]\n",
    "some_label = y[913]\n",
    "some_digit_image = some_digit.reshape(28,28) # X[12345]를 28x28 행렬로 재배열\n",
    "\n",
    "plt.imshow(some_digit_image, cmap=\"binary\")\n",
    "plt.axis(\"off\")\n",
    "plt.show() # 이미지 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The answer is : {0}\".format(some_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:] # train : test = 6 : 1\n",
    "y_train_8, y_test_8 = (y_train==8), (y_test==8) # 이진 분류기를 먼저 만들어보자 [8 or ~8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf = SGDClassifier(random_state=32) # Stochastic Gradient Descent Classifier을 모델로 사용\n",
    "sgd_clf.fit(X_train, y_train_8) # 훈련(학습) 개시 (fit)\n",
    "sgd_clf.predict([some_digit]) # 모델에 입력을 넣으면 결과가 출력된다. (predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(sgd_clf, X_train, y_train_8, cv=3, scoring=\"accuracy\") # 3겹 교차검증 후 정확도 각각 체크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Never8(BaseEstimator): # 무조건 8이 아니라고 하는 모델을 사용 \n",
    "    def fit(self, X, y=None): # fit = 훈련 (학습안함)\n",
    "        return self\n",
    "    def predict(self, X): # predict = 예측 (무조건 false)\n",
    "        return np.zeros((len(X),1),dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "never_8_clf = Never8()\n",
    "cross_val_score(never_8_clf, X_train, y_train_8, cv=3, scoring=\"accuracy\") # 3겹 교차검증 재실시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_8_pred = cross_val_predict(sgd_clf, X_train, y_train_8, cv=3) # 3겹 교차검증 후 predict 저장\n",
    "confusion_matrix(y_train_8, y_train_8_pred) # predict와 label로 오차행렬 생성 (TN,FP,FN,TP)\n",
    "confusion_matrix(y_train_8, y_train_8) # 만약 predict가 100% 정확할 경우 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_train_8, y_train_8_pred) # precision = True라고 예측한 것중 True 비율 = 63.1%\n",
    "recall_score(y_train_8, y_train_8_pred) # recall = True 중 True라고 예측한 비율 = 63.4%\n",
    "f1_score(y_train_8, y_train_8_pred) # F1 = 두 점수의 조화평균, 임계값에 따른 모델의 성능 제시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores = cross_val_predict(sgd_clf, X_train, y_train_8, cv=3, method=\"decision_function\") # 3겹 교차검증 후 score 저장\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_train_8, y_scores) # PR곡선 구하기 [recall x precision]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pr_threshold_curve(precisions, recalls, thresholds):\n",
    "    plt.plot(thresholds, precisions[:-1], \"b-\", label=\"precision\")\n",
    "    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"recall\")\n",
    "    f1_scores = 2/(1/precisions + 1/recalls)\n",
    "    plt.plot(thresholds, f1_scores[:-1], \"k-\", label=\"F1\")\n",
    "def plot_pr_curve(precisions, recalls):\n",
    "    plt.plot(recalls[:-1], precisions[:-1], \"g-\", label=\"PR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pr_threshold_curve(precisions, recalls, thresholds)\n",
    "plt.show() # precision과 recall은 임계값에 대해 대립 관계라는 것을 알 수 있음 \n",
    "plot_pr_curve(precisions, recalls)\n",
    "plt.show() # PR곡선 = x축이 recall, y축이 precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_90p = thresholds[np.argmax(precisions >= 0.90)]\n",
    "y_train_pred_90p = (y_scores >= threshold_90p) # predict는 score과 threshold의 비교로 얻어낼 수 있음\n",
    "precision_score(y_train_8, y_train_pred_90p)\n",
    "recall_score(y_train_8, y_train_pred_90p) # precision은 90% 이상인 반면, recall은 낮게 나옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FPR, TPR, thresholds = roc_curve(y_train_8, y_scores) # ROC곡선 구하기 [FP_rate x TP_rate] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(FPR, TPR, label=None, color=\"blue\"):\n",
    "    plt.plot(FPR, TPR, color=color, linewidth=2, label=label)\n",
    "    plt.plot([0,1],[0,1],'k--')\n",
    "plot_roc_curve(FPR,TPR) # FP_rate = False 중 True라고 예측, TP = True 중 True라고 예측한 비율\n",
    "plt.show() # ROC곡선 = x축이 FP_rate, y축이 TP_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_clf = RandomForestClassifier(random_state=42) # Random Forest Classifier을 모델로 사용\n",
    "y_probas_forest = cross_val_predict(forest_clf, X_train, y_train_8, cv=3, method=\"predict_proba\") # 3겹 교차검증 후 probability 저장[0~1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores_forest = y_probas_forest[:,1] # Forest가 만든 확률배열 중 Tree 하나를 골라서 점수로 사용\n",
    "FPR_forest, TPR_forest, thresholds_forest = roc_curve(y_train_8, y_scores_forest) # ROC곡선 구하기 (SGD와 동일)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(FPR_forest, TPR_forest, \"Random Forest\", \"blue\") \n",
    "plot_roc_curve(FPR, TPR, \"SGD\", \"green\") \n",
    "plt.show() # Random Forest와 SGD의 두 ROC곡선 비교\n",
    "roc_auc_score(y_train_8, y_scores) \n",
    "roc_auc_score(y_train_8, y_scores_forest) # 두 ROC곡선의 AUC 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small = X_train[1:4000] # SVM은 시간복잡도가 많이 나가기 때문\n",
    "y_train_small = y_train[1:4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf = SVC() # Support Vector Machine Classfier을 모델로 사용 (다중 클래스 분류과제)\n",
    "svm_clf.fit(X_train_small, y_train_small) # fit\n",
    "svm_clf.predict([some_digit]) # predict \n",
    "cross_val_score(svm_clf, X_train_small, y_train_small, cv=3, scoring=\"accuracy\") # 3겹 교차검증 후 정확도 체크 (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf.classes_ # 모델이 분류하는 레이블의 목록\n",
    "some_digit_scores = svm_clf.decision_function([some_digit]) # 하나의 샘플에 10가지 score이 저장됨\n",
    "some_digit_scores\n",
    "np.argmax(some_digit_scores) # 10가지 score 중 최대값을 가지는 index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf.fit(X_train, y_train) # fit - SGD도 다중 클래스 분류에 사용가능\n",
    "sgd_clf.predict([some_digit]) # predict\n",
    "cross_val_score(sgd_clf, X_train, y_train, cv=3, scoring=\"accuracy\") # 3겹 교차검증 후 정확도 각각 체크 (SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler() # SGD팁 - 입력 데이터의 분포를 스케일링함 \n",
    "X_train_scaled = scaler.fit_transform(X_train.astype(np.float64))\n",
    "cross_val_score(sgd_clf, X_train_scaled, y_train, cv=3, scoring=\"accuracy\") # 교차검증 시 정확도 향상 확인 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_svm_train_pred = cross_val_predict(svm_clf, X_train_small, y_train_small, cv=3) # SVM 3겹 교차검증 후 predict 저장\n",
    "svm_conf_mx = confusion_matrix(y_train_small, y_svm_train_pred) # predict와 label로 오차행렬 생성\n",
    "svm_conf_mx # 다중분류의 오차행렬(가로 predict / 세로 label)\n",
    "plt.matshow(svm_conf_mx, cmap=plt.cm.gray) # 대각선 위치가 밝아야 분류가 잘된것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = svm_conf_mx / svm_conf_mx.sum(axis=1, keepdims=True) # Normalize\n",
    "np.fill_diagonal(temp, 0) # 대각선 영역 제거\n",
    "plt.matshow(temp, cmap=plt.cm.gray) # 어디에서 오차가 심한지 확인 가능 (4-9,7-9,3-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = cross_val_predict(sgd_clf, X_train, y_train, cv=3) # SGD로 같은 과정 반복\n",
    "conf_mx = confusion_matrix(y_train, y_train_pred)\n",
    "conf_mx \n",
    "plt.matshow(conf_mx, cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = conf_mx / conf_mx.sum(axis=1, keepdims=True) # Normalize\n",
    "np.fill_diagonal(temp, 0) # 대각선 영역 제거\n",
    "plt.matshow(temp, cmap=plt.cm.gray) # 어디에서 오차가 심한지 확인 가능 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_97 = X_train[(y_train == 9) & (y_train_pred == 7)]\n",
    "X_79 = X_train[(y_train == 7) & (y_train_pred == 9)]\n",
    "X_49 = X_train[(y_train == 4) & (y_train_pred == 9)]\n",
    "X_94 = X_train[(y_train == 9) & (y_train_pred == 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm\n",
    "def plot_digits(instances, images_per_row=10, **options): # 이미지 그리는 함수\n",
    "    size = 28\n",
    "    images_per_row = min(len(instances), images_per_row)\n",
    "    images = [instance.reshape(size,size) for instance in instances]\n",
    "    n_rows = (len(instances) - 1) // images_per_row + 1\n",
    "    row_images = []\n",
    "    n_empty = n_rows * images_per_row - len(instances)\n",
    "    images.append(np.zeros((size, size * n_empty)))\n",
    "    for row in range(n_rows):\n",
    "        rimages = images[row * images_per_row : (row + 1) * images_per_row]\n",
    "        row_images.append(np.concatenate(rimages, axis=1))\n",
    "    image = np.concatenate(row_images, axis=0)\n",
    "    plt.imshow(image, cmap = matplotlib.cm.binary, **options)\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8)) # 오답노트 출력하기\n",
    "plt.subplot(221); plot_digits(X_97[:25], images_per_row=5) \n",
    "plt.subplot(222); plot_digits(X_79[:25], images_per_row=5)\n",
    "plt.subplot(223); plot_digits(X_49[:25], images_per_row=5)\n",
    "plt.subplot(224); plot_digits(X_94[:25], images_per_row=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_large = (y_train >= 7) # 7이상\n",
    "y_train_odd = (y_train%2 == 1) # 홀수\n",
    "y_multilabel = np.c_[y_train_large, y_train_odd] # \"다중 레이블 분류과제\" - 예측해야 하는 항목 2개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_clf = KNeighborsClassifier() # K-Neighbors Classifier을 모델로 사용\n",
    "knn_clf.fit(X_train, y_multilabel) # fit\n",
    "knn_clf.predict([some_digit]) # predict(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_knn_train_pred = cross_val_predict(knn_clf, X_train, y_multilabel, cv=3) # KNN 3겹 교차검증 후 predict 저장\n",
    "f1_score(y_multilabel, y_knn_train_pred, average=\"macro\") # predict와 label로 F1 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = np.random.randint(0, 100, (len(X_train), 784))\n",
    "X_train_noise = X_train + noise\n",
    "noise = np.random.randint(0, 100, (len(X_test), 784)) \n",
    "X_test_noise = X_test + noise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_clf.fit(X_train_noise, X_train) # \"다중 출력 분류과제\" - 사진 노이즈 제거\n",
    "clean_digit = knn_clf.predict([X_test_noise[8293]])\n",
    "plot_digits(clean_digit)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
